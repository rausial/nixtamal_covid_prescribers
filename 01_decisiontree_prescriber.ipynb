{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp decisiontree_prescriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree prescriber\n",
    "\n",
    "> This module finds importance weights for NPIs. The rationale is the following. For every region we can adjust a random forest that predicts the impact of a combination of NPIs in a given country. We will measure the impact with five levels (0-4) the represent the categories: Very bad, Bad, Neutral, Good, Very good. This categories are defined with respect to how well they should work in reducing the number of new cases once the interventions are implemented.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "from covid_xprize.standard_predictor import xprize_predictor\n",
    "\n",
    "from nixtamal_covid import data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def make_training_df(sim_df, lookup_days):\n",
    "    ''' Create column with percentage change in the future, given the rows NPI and a number of days in the future'''\n",
    "    \n",
    "    df = sim_df.copy()\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    df['CumCases'] = df.groupby(['GeoID', 'SimCode'])['PredNewCases'].transform('cumsum')\n",
    "    df[f'CumCases_next{lookup_days}'] = df.groupby(['GeoID',\n",
    "                                                    'SimCode'])['CumCases'].transform('shift',\n",
    "                                                                                        -lookup_days)\n",
    "    df[f'CumCases_{lookup_days}'] = df.groupby(['GeoID',\n",
    "                                                'SimCode'])['CumCases'].transform('shift',\n",
    "                                                                                  lookup_days)\n",
    "    \n",
    "    df[f'SmthCases_{lookup_days}'] = (df['CumCases'] -\n",
    "                                      df[f'CumCases_{lookup_days}']) / lookup_days\n",
    "    \n",
    "    df[f'SmthCases_next{lookup_days}'] = (df[f'CumCases_next{lookup_days}'] -\n",
    "                                          df['CumCases']) / lookup_days\n",
    "    \n",
    "    df[f'PctChange_{lookup_days}'] = (df[f'SmthCases_next{lookup_days}'] -\n",
    "                                      df[f'SmthCases_{lookup_days}']) / (df[f'SmthCases_{lookup_days}'] + 1)\n",
    "    \n",
    "    df = df[df[f'CumCases_{lookup_days}'].notna() & df[f'CumCases_next{lookup_days}'].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def train_random_forests(df):\n",
    "    '''Training data. X is given by the current IPS, new cases per 100k habitants and country data.\n",
    "    Y is given by the NIPs that give the lowest number of new cases '''\n",
    "    \n",
    "    geo_ids = df.GeoID.unique()\n",
    "    npi_importances = {}\n",
    "    geoid_rfs = {}\n",
    "    for geo_id in geo_ids:\n",
    "        geo_data = df[df.GeoID == geo_id]\n",
    "        regr = RandomForestRegressor(random_state=0)\n",
    "        regr.fit(geo_data[xprize_predictor.NPI_COLUMNS], geo_data[f'PctChange_{lookup_days}'])\n",
    "        npi_importances.update({geo_id: regr.feature_importances_})\n",
    "        #geoid_rfs.update({geo_id: regr})\n",
    "    \n",
    "    npi_importance_df = pd.DataFrame.from_dict(npi_importances, orient='index')\n",
    "    npi_importance_df.columns = [xprize_predictor.NPI_COLUMNS]\n",
    "    \n",
    "    npi_importance_df = npi_importance_df.reset_index()\n",
    "    npi_importance_df.rename(columns={'index': 'GeoID'}, inplace=True)\n",
    "    \n",
    "    return npi_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def make_clusters(npi_importance_df):\n",
    "    bandwidth = estimate_bandwidth(npi_importance_df.drop(columns='GeoID'), quantile=0.1)\n",
    "    ms = MeanShift(bandwidth=bandwidth)\n",
    "\n",
    "    ms.fit(npi_importance_df.drop(columns='GeoID'))\n",
    "    \n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pickle:\n",
    "    with open('simulations_df.pkl', 'rb') as f:\n",
    "        sim_df = pickle.load(f)\n",
    "else:\n",
    "    sim_df = data.load_predictor_simulations()\n",
    "    with open('simulations_df.pkl', 'wb') as f:\n",
    "        pickle.dump(sim_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_training_df(sim_df, lookup_days)\n",
    "del sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['GeoID'] == 'Mexico') & (df.SimCode == '332423202324')].plot(y=[f'SmthCases_{lookup_days}',\n",
    "                                                                       f'SmthCases_next{lookup_days}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['GeoID'] == 'Mexico') &\n",
    "   (df.SimCode == '332423202324')].plot(y=f'PctChange_{lookup_days}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df = train_random_forests(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df.to_csv('npi_importances.csv', index=False)\n",
    "npi_importance_df = pd.read_csv('npi_importances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_imp = npi_importance_df.query('GeoID == \"Mexico\"').copy()\n",
    "npi_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_imp.drop(columns='GeoID', inplace=True)\n",
    "npi_imp*npi_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df.query('GeoID == \"Spain\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df.query('GeoID == \"Mexico\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = make_clusters(npi_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ms.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_importance_df[ms.labels_ == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
