{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> This module generates a dataset of new cases predictions for 2020. The dataset is meant to train and test prescriptors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from covid_xprize.standard_predictor import *\n",
    "from covid_xprize.validation import scenario_generator\n",
    "\n",
    "from covid_xprize.scoring.predictor_scoring import *\n",
    "from covid_xprize.scoring.prescriptor_scoring import *\n",
    "\n",
    "from covid_xprize.examples.prescriptors.neat import utils \n",
    "from covid_xprize.standard_predictor import xprize_predictor\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = xprize_predictor.XPrizePredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cases_and_stringency_for_prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xprize_predictor.NPI_COLUMNS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generator.MAX_NPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def predict_cases(start, end, ips_historic=None , historical_cutoff_date='2020-07-31'):\n",
    "    ''' Predict cases for every region in the specified time range for every combination of NPIs '''\n",
    "    \n",
    "    predictor = xprize_predictor.XPrizePredictor()\n",
    "    scenario = scenario_generator.generate_scenario(start_date,\n",
    "                      end_date,\n",
    "                      latest_df,\n",
    "                      countries=countries,\n",
    "                      scenario=\"Historical\")\n",
    "    \n",
    "    return scenario\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def npis_combinations(fixed_npis={}):\n",
    "    ''' Generate all combinations of NPI values, excludig NPIs specified in de 'exclude_npis' list'''\n",
    "    \n",
    "    npi_values = [list(range(npi_max)) for npi_max in scenario_generator.MAX_NPIS]\n",
    "    num_combinations = np.product(list(map(len, npi_values)))\n",
    "    \n",
    "    npi_combinations = list(itertools.product(*npi_values))\n",
    "    assert len(npi_combinations), num_combinations\n",
    "        \n",
    "    return pd.DataFrame(npi_combinations, columns=scenario_generator.NPI_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def load_predictor_simulations(path='data/simulations'):\n",
    "    sim_csvs = list(Path('data/simulations').rglob('*.csv'))\n",
    "    sim_dfs = []\n",
    "    \n",
    "    for sim_csv in sim_csvs:\n",
    "        sim_code = sim_csv.stem[:12]\n",
    "        nips = list(map(int, list(sim_code)))\n",
    "        \n",
    "        df = pd.read_csv(sim_csv, low_memory=False)\n",
    "        df = df.melt(id_vars='Date')\n",
    "        df.rename(columns={'variable': 'GeoID', 'value': 'PredNewCases'}, inplace=True)\n",
    "        df[xprize_predictor.NPI_COLUMNS] = nips\n",
    "        df['SimCode'] = sim_code\n",
    "        sim_dfs.append(df)\n",
    "        \n",
    "    return pd.concat(sim_dfs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = load_predictor_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def generate_scenario_multiverse(alt_universe_start_date='2020-08-01',\n",
    "                                 alt_universe_end_date='2021-01-01',\n",
    "                                 countries=None):\n",
    "    start_date = pd.to_datetime(alt_universe_start_date, format='%Y-%m-%d')\n",
    "    end_date = pd.to_datetime(alt_universe_end_date, format='%Y-%m-%d')\n",
    "\n",
    "    # nips_combinations = npis_combinations()\n",
    "\n",
    "    historical_df = predictor.df.copy()\n",
    "    historical_df['NextNewCases'] = historical_df.groupby('GeoID')['SmoothNewCases'].transform('shift', -14)\n",
    "    historical_df['RateNewCases'] = -historical_df.groupby('GeoID')['SmoothNewCases'].transform('pct_change', -14)\n",
    "    historical_df['RateNewDeaths'] = -historical_df.groupby('GeoID')['SmoothNewDeaths'].transform('pct_change', -14)\n",
    "    \n",
    "    prediction_batches = []    \n",
    "    predictor = xprize_predictor.XPrizePredictor()\n",
    "    \n",
    "    num_shuffles = 3\n",
    "    for i in range(num_shuffles):\n",
    "        shuffle_geoids_history()\n",
    "    predictions = predictor.predict_from_df(start_date,\n",
    "                                            end_date,\n",
    "                                            nips_df=historical_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return historical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_str='2020-03-01'\n",
    "end_date_str='2021-01-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history_df = generate_scenario_multiverse(start_date_str, end_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history_df.query('GeoID == \"Mexico\"').tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history_df.to_csv('test_history_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_str='2020-06-01'\n",
    "end_date_str='2021-01-01'\n",
    "\n",
    "predict.predict(pd.to_datetime(start_date_str, yearfirst=True),\n",
    "                pd.to_datetime(end_date_str, yearfirst=True),\n",
    "                path_to_ips_file='ips_test_scenarios.csv',\n",
    "                output_file_path='./test_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = utils.prepare_historical_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df = load_dataset(geos_file='./countries_regions.csv')\n",
    "latest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
